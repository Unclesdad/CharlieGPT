# CharlieGPT Training Configuration for 7B Model on Raspberry Pi
# This config is for background training and doesn't affect the running bot

# Training Settings (7B model - optimized for Pi background training)
training:
  base_model: "Qwen/Qwen2.5-7B-Instruct"  # 7B model for better coherence
  output_dir: "./models/charliegpt-8b-lora"
  epochs: 1  # Single epoch to keep training time reasonable
  batch_size: 1  # Very small batch for Pi memory constraints
  learning_rate: 0.0002
  lora_rank: 8  # Keep low for memory
  lora_alpha: 16
  lora_dropout: 0.05
  max_seq_length: 256  # Keep short for speed

# Paths
paths:
  data_dir: "./data"
  processed_data_dir: "./processed_data"
  models_dir: "./models"
  vectordb_dir: "./vectordb"
  llama_cpp_path: "~/llama.cpp/build/bin"
